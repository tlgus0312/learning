{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98551eed-9a52-4cfb-b54b-5b542fe65876",
   "metadata": {},
   "source": [
    "# RNN 기반 텍스트 생성 (언어모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ee41de-39f6-4338-8160-c3055b0ffc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['경마장에 있는 말이 뛰고 있다',\n",
    "        '그의 말이 법이다',\n",
    "        '가는 말이 고와야 오는 말이 곱다']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e2732-3930-4349-a74b-b7b58e60d5ba",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f75dae-64db-4d4c-9ceb-f4ea48a6c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기:11\n",
      "max_feature:12\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "# tokenizing해서 indexing -> 단어 수 확인\n",
    "# 데이터를 준비하는 과정\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "vocab_size=len(tokenizer.word_index)\n",
    "max_feature=vocab_size+1\n",
    "print(f'단어 집합의 크기:{vocab_size}')\n",
    "print(f'max_feature:{max_feature}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea5ea71b-e50f-4a82-9c87-f25236a7f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체문장:[2, 3, 1, 4, 5]\n",
      "[]\n",
      "[[...]]\n",
      "[[...], [...]]\n",
      "[[...], [...], [...]]\n",
      "전체문장:[6, 1, 7]\n",
      "[[...], [...], [...], [...]]\n",
      "[[...], [...], [...], [...], [...]]\n",
      "전체문장:[8, 1, 9, 10, 1, 11]\n",
      "[[...], [...], [...], [...], [...], [...]]\n",
      "[[...], [...], [...], [...], [...], [...], [...]]\n",
      "[[...], [...], [...], [...], [...], [...], [...], [...]]\n",
      "[[...], [...], [...], [...], [...], [...], [...], [...], [...]]\n",
      "[[...], [...], [...], [...], [...], [...], [...], [...], [...], [...]]\n",
      "학습 데이터 수:6\n"
     ]
    }
   ],
   "source": [
    "# 언어 모델용 학습 데이터 만들기\n",
    "#print(tokenizer.word_index)\n",
    "\n",
    "sequence=list()\n",
    "for sent in corpus:\n",
    "    #integer encoding\n",
    "    indexed_sent = tokenizer.texts_to_sequences([sent])[0]\n",
    "    print(f'전체문장:{indexed_sent}')\n",
    "\n",
    "    #두번째 단어까지부터 시작해서 한단어씩 추가해서  학습데이터 생성\n",
    "    for i in range(1, len(indexed_sent)):\n",
    "        sequences=indexed_sent[:i+1]\n",
    "        print(sequence)\n",
    "        sequence.append(sequence)\n",
    "\n",
    "print(f'학습 데이터 수:{len(sequences)}')\n",
    "#앞에 패딩을 넣을 것이다.#패딩을 앞에다가 넣는 이유는?\n",
    "#short term \n",
    "#뒤에 반영하고싶은게 많이 남아있음 \n",
    "#셀스테이트 \n",
    "#입력과 정답을 구분 \n",
    "#1.integer encoding-> 문장길이까지 가져온다. range1부터 시작 \n",
    "#2.padding \n",
    "#3.입력 정답 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d54dbd60-3d19-4052-bad9-dd49a9719486",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m sequences:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m>\u001b[39mmaxlen:\n\u001b[0;32m      5\u001b[0m         maxlen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sequence)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#maxlen = max([len(sequence)for sequence in sequences])\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "# 모든 샘플에서 길이가 가장 긴 샘플의 길이 구하기\n",
    "maxlen=0\n",
    "for sequence in sequences:\n",
    "    if len(sequence)>maxlen:\n",
    "        maxlen = len(sequence)\n",
    "\n",
    "#maxlen = max([len(sequence)for sequence in sequences])\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5486d8-b275-4d0d-b96a-75239b961e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_sequences=pad_sequences(sequences, maxlen=maxlen)\n",
    "print(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17d9de-7fa9-47c1-b945-3cab767f0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터와 정답 데이터 분리\n",
    "import numpy as np \n",
    "np_sequences=np.array(padded_sequences)\n",
    "X = np_sequences[:,:-1]\n",
    "y=np_sequences[:,-1]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c7acf-6e17-406e-98bb-1f5a1f3e7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터 단어 11개를 카테고리로 one-hot-encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y=to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172fa79b-0d03-418c-a6f4-ec38584deeab",
   "metadata": {},
   "source": [
    "## 2. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e81b01-45fd-43eb-99ad-409c56d38fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축(레이어 설계+ activation)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LSTM\n",
    "\n",
    "input_units = max_features\n",
    "embedding_dim = 10\n",
    "rnn_units = 32\n",
    "output_units = max_features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_units, embedding_dim))\n",
    "#Embedding(input_units, embedding_dim, input_length=max_len)\n",
    "\n",
    "# 모델을 나중에 사용할 때(배포할 때), 입력 길이를 자동으로 인식하지 못할 수 있어서\n",
    "# input_length를 미리 정해줘야 함 \n",
    "\n",
    "model.add(SimpleRNN(rnn_units))\n",
    "model.add(Dense(output_units, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1c9f733-0640-4bc8-b4bc-caa2ec3848a0",
   "metadata": {},
   "source": [
    "rnn_lang_model=[\n",
    "Embedding(input_units, embedding_dim),\n",
    "# SimpleRNN(rnn_units),\n",
    "LSTN\n",
    "Dense(output_units, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2869edf-29f3-48a1-9a4e-330c680e78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일(학습설계)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0d623-3659-4c49-80c0-00193195e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "model.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca94d3-4aaf-42f3-bd4b-a6f824460849",
   "metadata": {},
   "source": [
    "## 3. 첫 단어 입력 후 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601ad4f-78b1-4822-b8d4-4229bd2c489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어를 입력하고, 반복할 회수를 주면 문장 생성\n",
    "# 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "def sentence_generation(model, tokenizer, init_word, n): \n",
    "    current_word = init_word\n",
    "    sentence = ''\n",
    "\n",
    "    # n번 반복\n",
    "    for _ in range(n):\n",
    "        # Integer Encoding\n",
    "       sequence= tokenizer.texts_to_sequences([current_word])\n",
    "        # Padding\n",
    "       padded_sequence=pad_sequences(sequence, maxlen=maxlen-1)\n",
    "\n",
    "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "       result = model.predict(padded_sequence, verbose=0)\n",
    "       print(result)\n",
    "        #print(result)\n",
    "       result_index=np.argmax(result)\n",
    "        print(result_index)\n",
    "        # 예측한 인덱스의 단어 가져오기\n",
    "       word=tokenizer.index_word[result_index]\n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "                    \n",
    "\n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "       current_word = current_word+''+word\n",
    "        # 예측 단어를 문장에 저장\n",
    "       sentence = sentence+''+word\n",
    "\n",
    "    return init_word + sentence\n",
    "sentence_generation(model, tokenizer, '경마장에', 4)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5ede9-a6f7-4651-aa4f-dd7e71ca83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation(model, tokenizer, input('시작 단어열 입력:'),int(input('생성단어수:')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2d1b9-1689-4587-80fe-30efdafeaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어를 입력하고, 반복할 회수를 주면 문장 생성\n",
    "# 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "def sentence_generation(model, tokenizer, init_word, n): \n",
    "    current_word = init_word\n",
    "    sentence = ''\n",
    "\n",
    "    # n번 반복\n",
    "    for _ in range(n):\n",
    "        # Integer Encoding\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        # Padding\n",
    "        padded = pad_sequences([encoded], maxlen=max_len-1) #, padding='pre')\n",
    "\n",
    "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict(padded, verbose=0)\n",
    "        #print(result)\n",
    "        result_index = np.argmax(result, axis=1)\n",
    "\n",
    "        # 예측한 인덱스의 단어 가져오기\n",
    "        for word, index in tokenizer.word_index.items(): \n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "            if index == result_index:                break\n",
    "\n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        current_word = current_word + ' '  + word\n",
    "\n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence\n",
    "\n",
    "sentence_generation(model, tokenizer, '경마장에', 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF210Py310)",
   "language": "python",
   "name": "tf210py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
